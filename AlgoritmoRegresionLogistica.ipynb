{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yeyoc\\AppData\\Local\\Temp\\ipykernel_13412\\1745703392.py:2: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  new_df=  pd.read_csv ('archivos/NewDataAll2.csv')\n"
     ]
    }
   ],
   "source": [
    "enfermedades = pd.read_excel('archivos/CIE.xlsx')\n",
    "new_df=  pd.read_csv ('archivos/NewDataAll2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>depreg</th>\n",
       "      <th>mupreg</th>\n",
       "      <th>mesreg</th>\n",
       "      <th>añoreg</th>\n",
       "      <th>depocu</th>\n",
       "      <th>mupocu</th>\n",
       "      <th>sexo</th>\n",
       "      <th>diaocu</th>\n",
       "      <th>mesocu</th>\n",
       "      <th>...</th>\n",
       "      <th>ecidif</th>\n",
       "      <th>dnadif</th>\n",
       "      <th>mnadif</th>\n",
       "      <th>nacdif</th>\n",
       "      <th>dredif</th>\n",
       "      <th>mredif</th>\n",
       "      <th>caudef</th>\n",
       "      <th>asist</th>\n",
       "      <th>ocur</th>\n",
       "      <th>cerdef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>505</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>505</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>Y214</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>X919</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>2206</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>2206</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>X959</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>201</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>201</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>V899</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>X709</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953746</th>\n",
       "      <td>95996</td>\n",
       "      <td>9</td>\n",
       "      <td>901</td>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>901</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>99</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>99</td>\n",
       "      <td>9999</td>\n",
       "      <td>R99X</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953747</th>\n",
       "      <td>95997</td>\n",
       "      <td>10</td>\n",
       "      <td>1001</td>\n",
       "      <td>11</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>1001</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>99</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>99</td>\n",
       "      <td>9999</td>\n",
       "      <td>J984</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953748</th>\n",
       "      <td>95998</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>6</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>99</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>99</td>\n",
       "      <td>9999</td>\n",
       "      <td>U071</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953749</th>\n",
       "      <td>95999</td>\n",
       "      <td>9</td>\n",
       "      <td>901</td>\n",
       "      <td>2</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>901</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>99</td>\n",
       "      <td>9999</td>\n",
       "      <td>9999</td>\n",
       "      <td>99</td>\n",
       "      <td>9999</td>\n",
       "      <td>K709</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953750</th>\n",
       "      <td>96000</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>320</td>\n",
       "      <td>99</td>\n",
       "      <td>9999</td>\n",
       "      <td>X599</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>953751 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  depreg  mupreg  mesreg  añoreg  depocu  mupocu  sexo   \n",
       "0                0       5     505       1       9       5     505     1  \\\n",
       "1                1       1     101       9       9       1     101     1   \n",
       "2                2      22    2206       9       9      22    2206     2   \n",
       "3                3       2     201      12       9       2     201     1   \n",
       "4                4       1     101       5       9       1     101     2   \n",
       "...            ...     ...     ...     ...     ...     ...     ...   ...   \n",
       "953746       95996       9     901       4    2020       9     901     1   \n",
       "953747       95997      10    1001      11    2020      10    1001     1   \n",
       "953748       95998       1     101       6    2020       1     101     1   \n",
       "953749       95999       9     901       2    2020       9     901     1   \n",
       "953750       96000       1     101       1    2020       1     101     1   \n",
       "\n",
       "        diaocu  mesocu  ...  ecidif  dnadif  mnadif  nacdif  dredif mredif   \n",
       "0            2       1  ...       1       1     101       0       1    101  \\\n",
       "1           27       9  ...       1       1     101       0       1    101   \n",
       "2           23       8  ...       1       1     101       0       1    101   \n",
       "3            5      12  ...       1       1     101       0       1    101   \n",
       "4            7       5  ...       2       1     101       0       1    101   \n",
       "...        ...     ...  ...     ...     ...     ...     ...     ...    ...   \n",
       "953746       7       4  ...       9      99    9999    9999      99   9999   \n",
       "953747      22      10  ...       9      99    9999    9999      99   9999   \n",
       "953748      27       6  ...       9      99    9999    9999      99   9999   \n",
       "953749      23       2  ...       9      99    9999    9999      99   9999   \n",
       "953750      22       1  ...       2       1     101     320      99   9999   \n",
       "\n",
       "        caudef  asist  ocur cerdef  \n",
       "0         Y214      1     3      1  \n",
       "1         X919      4     3      1  \n",
       "2         X959      4     3      2  \n",
       "3         V899      4     3      1  \n",
       "4         X709      4     3      1  \n",
       "...        ...    ...   ...    ...  \n",
       "953746    R99X      1     1      1  \n",
       "953747    J984      5     6      9  \n",
       "953748    U071      1     1      1  \n",
       "953749    K709      1     1      1  \n",
       "953750    X599      1     1      1  \n",
       "\n",
       "[953751 rows x 23 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['caudef']\n",
    "enfermedades2 = enfermedades.copy()\n",
    "enfermedades2.loc[enfermedades2['CAUSA'].str.len() == 3, 'CAUSA'] = enfermedades2.loc[enfermedades2['CAUSA'].str.len() == 3, 'CAUSA'] + \"X\"\n",
    "enfermedades2\n",
    "\n",
    "new_df2 = pd.merge(new_df, enfermedades2, left_on='caudef', right_on='CAUSA', how='left')\n",
    "\n",
    "new_df2 = new_df2.dropna()\n",
    "causas_infecciones = new_df2.loc[new_df2[\"DESCRIP\"].str.contains(\"Infecciones|infecciones|infeccion|Infección|Infeccion|infección\")]\n",
    "\n",
    "causas_vih = new_df2.loc[new_df2[\"DESCRIP\"].str.contains(\"VIH|vih|SIDA\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df2['VIH'] = 0\n",
    "indices_vih = new_df2[new_df2['DESCRIP'] .str.contains(\"VIH|vih|SIDA\")].index\n",
    "new_df2.loc[indices_vih, 'VIH'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>depreg</th>\n",
       "      <th>mupreg</th>\n",
       "      <th>mesreg</th>\n",
       "      <th>añoreg</th>\n",
       "      <th>depocu</th>\n",
       "      <th>mupocu</th>\n",
       "      <th>sexo</th>\n",
       "      <th>diaocu</th>\n",
       "      <th>mesocu</th>\n",
       "      <th>...</th>\n",
       "      <th>nacdif</th>\n",
       "      <th>dredif</th>\n",
       "      <th>mredif</th>\n",
       "      <th>caudef</th>\n",
       "      <th>asist</th>\n",
       "      <th>ocur</th>\n",
       "      <th>cerdef</th>\n",
       "      <th>CAUSA</th>\n",
       "      <th>DESCRIP</th>\n",
       "      <th>VIH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>505</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>505</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>Y214</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Y214</td>\n",
       "      <td>Ahogamiento y sumersión, de intención no deter...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>X919</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>X919</td>\n",
       "      <td>Agresión por ahorcamiento, estrangulamiento y ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>2206</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>2206</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>X959</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>X959</td>\n",
       "      <td>Agresión con disparo de otras armas de fuego, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>201</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>201</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>V899</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>V899</td>\n",
       "      <td>Persona lesionada en accidente de vehículo no ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>X709</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>X709</td>\n",
       "      <td>Lesión autoinfligida intencionalmente por ahor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953745</th>\n",
       "      <td>95995</td>\n",
       "      <td>5</td>\n",
       "      <td>501</td>\n",
       "      <td>12</td>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "      <td>503</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>9999</td>\n",
       "      <td>99</td>\n",
       "      <td>9999</td>\n",
       "      <td>X480</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>X480</td>\n",
       "      <td>Envenenamiento accidental por, y exposición a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953746</th>\n",
       "      <td>95996</td>\n",
       "      <td>9</td>\n",
       "      <td>901</td>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>901</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>9999</td>\n",
       "      <td>99</td>\n",
       "      <td>9999</td>\n",
       "      <td>R99X</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>R99X</td>\n",
       "      <td>Otras causas mal definidas y las no especifica...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953747</th>\n",
       "      <td>95997</td>\n",
       "      <td>10</td>\n",
       "      <td>1001</td>\n",
       "      <td>11</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>1001</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>9999</td>\n",
       "      <td>99</td>\n",
       "      <td>9999</td>\n",
       "      <td>J984</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>J984</td>\n",
       "      <td>Otros trastornos del pulmón</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953749</th>\n",
       "      <td>95999</td>\n",
       "      <td>9</td>\n",
       "      <td>901</td>\n",
       "      <td>2</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>901</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>9999</td>\n",
       "      <td>99</td>\n",
       "      <td>9999</td>\n",
       "      <td>K709</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>K709</td>\n",
       "      <td>Enfermedad hepática alcohólica, no especificada</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953750</th>\n",
       "      <td>96000</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>320</td>\n",
       "      <td>99</td>\n",
       "      <td>9999</td>\n",
       "      <td>X599</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>X599</td>\n",
       "      <td>Exposición a factores no especificados, causan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>927641 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  depreg  mupreg  mesreg  añoreg  depocu  mupocu  sexo   \n",
       "0                0       5     505       1       9       5     505     1  \\\n",
       "1                1       1     101       9       9       1     101     1   \n",
       "2                2      22    2206       9       9      22    2206     2   \n",
       "3                3       2     201      12       9       2     201     1   \n",
       "4                4       1     101       5       9       1     101     2   \n",
       "...            ...     ...     ...     ...     ...     ...     ...   ...   \n",
       "953745       95995       5     501      12    2020       5     503     1   \n",
       "953746       95996       9     901       4    2020       9     901     1   \n",
       "953747       95997      10    1001      11    2020      10    1001     1   \n",
       "953749       95999       9     901       2    2020       9     901     1   \n",
       "953750       96000       1     101       1    2020       1     101     1   \n",
       "\n",
       "        diaocu  mesocu  ...  nacdif  dredif  mredif  caudef  asist ocur   \n",
       "0            2       1  ...       0       1     101    Y214      1    3  \\\n",
       "1           27       9  ...       0       1     101    X919      4    3   \n",
       "2           23       8  ...       0       1     101    X959      4    3   \n",
       "3            5      12  ...       0       1     101    V899      4    3   \n",
       "4            7       5  ...       0       1     101    X709      4    3   \n",
       "...        ...     ...  ...     ...     ...     ...     ...    ...  ...   \n",
       "953745      27       7  ...    9999      99    9999    X480      9    6   \n",
       "953746       7       4  ...    9999      99    9999    R99X      1    1   \n",
       "953747      22      10  ...    9999      99    9999    J984      5    6   \n",
       "953749      23       2  ...    9999      99    9999    K709      1    1   \n",
       "953750      22       1  ...     320      99    9999    X599      1    1   \n",
       "\n",
       "        cerdef  CAUSA                                            DESCRIP VIH  \n",
       "0            1   Y214  Ahogamiento y sumersión, de intención no deter...   0  \n",
       "1            1   X919  Agresión por ahorcamiento, estrangulamiento y ...   0  \n",
       "2            2   X959  Agresión con disparo de otras armas de fuego, ...   0  \n",
       "3            1   V899  Persona lesionada en accidente de vehículo no ...   0  \n",
       "4            1   X709  Lesión autoinfligida intencionalmente por ahor...   0  \n",
       "...        ...    ...                                                ...  ..  \n",
       "953745       9   X480  Envenenamiento accidental por, y exposición a ...   0  \n",
       "953746       1   R99X  Otras causas mal definidas y las no especifica...   0  \n",
       "953747       9   J984                        Otros trastornos del pulmón   0  \n",
       "953749       1   K709    Enfermedad hepática alcohólica, no especificada   0  \n",
       "953750       1   X599  Exposición a factores no especificados, causan...   0  \n",
       "\n",
       "[927641 rows x 26 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df2.loc[new_df2[\"DESCRIP\"].str.contains(\"VIH|vih|SIDA\")]\n",
    "new_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0, '922577'), Text(0, 0, '5064')]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from seaborn import heatmap, countplot\n",
    "\n",
    "hist = countplot(new_df2, x=\"VIH\")\n",
    "hist.bar_label(hist.containers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>depreg</th>\n",
       "      <th>mupreg</th>\n",
       "      <th>mesreg</th>\n",
       "      <th>añoreg</th>\n",
       "      <th>depocu</th>\n",
       "      <th>mupocu</th>\n",
       "      <th>sexo</th>\n",
       "      <th>diaocu</th>\n",
       "      <th>mesocu</th>\n",
       "      <th>...</th>\n",
       "      <th>nacdif</th>\n",
       "      <th>dredif</th>\n",
       "      <th>mredif</th>\n",
       "      <th>caudef</th>\n",
       "      <th>asist</th>\n",
       "      <th>ocur</th>\n",
       "      <th>cerdef</th>\n",
       "      <th>CAUSA</th>\n",
       "      <th>DESCRIP</th>\n",
       "      <th>VIH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>505</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>505</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>3337</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3337</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>3240</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3240</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>2206</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>2206</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>3262</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3262</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>201</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>201</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>2849</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2849</td>\n",
       "      <td>2490</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>3186</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3186</td>\n",
       "      <td>1690</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953745</th>\n",
       "      <td>95995</td>\n",
       "      <td>5</td>\n",
       "      <td>501</td>\n",
       "      <td>12</td>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "      <td>503</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>9999</td>\n",
       "      <td>99</td>\n",
       "      <td>9999</td>\n",
       "      <td>3123</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>3123</td>\n",
       "      <td>989</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953746</th>\n",
       "      <td>95996</td>\n",
       "      <td>9</td>\n",
       "      <td>901</td>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>901</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>9999</td>\n",
       "      <td>99</td>\n",
       "      <td>9999</td>\n",
       "      <td>2823</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2823</td>\n",
       "      <td>2095</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953747</th>\n",
       "      <td>95997</td>\n",
       "      <td>10</td>\n",
       "      <td>1001</td>\n",
       "      <td>11</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>1001</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>9999</td>\n",
       "      <td>99</td>\n",
       "      <td>9999</td>\n",
       "      <td>1572</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1572</td>\n",
       "      <td>2373</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953749</th>\n",
       "      <td>95999</td>\n",
       "      <td>9</td>\n",
       "      <td>901</td>\n",
       "      <td>2</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>901</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>9999</td>\n",
       "      <td>99</td>\n",
       "      <td>9999</td>\n",
       "      <td>1751</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1751</td>\n",
       "      <td>868</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953750</th>\n",
       "      <td>96000</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>320</td>\n",
       "      <td>99</td>\n",
       "      <td>9999</td>\n",
       "      <td>3147</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3147</td>\n",
       "      <td>1147</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>927641 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  depreg  mupreg  mesreg  añoreg  depocu  mupocu  sexo   \n",
       "0                0       5     505       1       9       5     505     1  \\\n",
       "1                1       1     101       9       9       1     101     1   \n",
       "2                2      22    2206       9       9      22    2206     2   \n",
       "3                3       2     201      12       9       2     201     1   \n",
       "4                4       1     101       5       9       1     101     2   \n",
       "...            ...     ...     ...     ...     ...     ...     ...   ...   \n",
       "953745       95995       5     501      12    2020       5     503     1   \n",
       "953746       95996       9     901       4    2020       9     901     1   \n",
       "953747       95997      10    1001      11    2020      10    1001     1   \n",
       "953749       95999       9     901       2    2020       9     901     1   \n",
       "953750       96000       1     101       1    2020       1     101     1   \n",
       "\n",
       "        diaocu  mesocu  ...  nacdif  dredif  mredif  caudef  asist ocur   \n",
       "0            2       1  ...       0       1     101    3337      1    3  \\\n",
       "1           27       9  ...       0       1     101    3240      4    3   \n",
       "2           23       8  ...       0       1     101    3262      4    3   \n",
       "3            5      12  ...       0       1     101    2849      4    3   \n",
       "4            7       5  ...       0       1     101    3186      4    3   \n",
       "...        ...     ...  ...     ...     ...     ...     ...    ...  ...   \n",
       "953745      27       7  ...    9999      99    9999    3123      9    6   \n",
       "953746       7       4  ...    9999      99    9999    2823      1    1   \n",
       "953747      22      10  ...    9999      99    9999    1572      5    6   \n",
       "953749      23       2  ...    9999      99    9999    1751      1    1   \n",
       "953750      22       1  ...     320      99    9999    3147      1    1   \n",
       "\n",
       "        cerdef  CAUSA  DESCRIP  VIH  \n",
       "0            1   3337      169    0  \n",
       "1            1   3240      129    0  \n",
       "2            2   3262       80    0  \n",
       "3            1   2849     2490    0  \n",
       "4            1   3186     1690    0  \n",
       "...        ...    ...      ...  ...  \n",
       "953745       9   3123      989    0  \n",
       "953746       1   2823     2095    0  \n",
       "953747       9   1572     2373    0  \n",
       "953749       1   1751      868    0  \n",
       "953750       1   3147     1147    0  \n",
       "\n",
       "[927641 rows x 26 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming you have a pandas DataFrame called 'data' with the 'cause' column\n",
    "encoder = LabelEncoder()\n",
    "new_df2['caudef'] = encoder.fit_transform(new_df2['caudef'])\n",
    "new_df2['CAUSA'] = encoder.fit_transform(new_df2['CAUSA'])\n",
    "new_df2['DESCRIP'] = encoder.fit_transform(new_df2['DESCRIP'])\n",
    "\n",
    "new_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import numpy as np\n",
    "\n",
    "# Iterate over each column and replace non-numeric values with 0\n",
    "for column in data.columns:\n",
    "    new_df2[column] = pd.to_numeric(data[column], errors='coerce').fillna(0)\n",
    "\n",
    "# Continue with your data analysis using the modified dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar las características y la variable objetivo\n",
    "#X = new_df2[['Depreg', 'Mupreg', 'Mesreg', 'Añoreg', 'Depocu', 'Mupocu', 'Sexo', 'Diaocu', 'Mesocu', 'Añoocu', 'Edadif', 'Perdif', 'Ecidif', 'Dnadif', 'Nacdif', 'Dredif', 'Mredif', 'Asist', 'Ocur', 'Cerdef']]\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X = new_df2.drop('VIH', axis=1)\n",
    "y = new_df2[\"VIH\"]\n",
    "\n",
    "\n",
    "#X = new_df2[['Edadif']]\n",
    "#y = new_df2['VIH']\n",
    "# Balancear las clases utilizando SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.25042866270621406\n",
      "R2: 0.7491418621683655\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "# Crear una instancia del modelo SVM y entrenarlo con diferentes parámetros\n",
    "linReg = LinearRegression()\n",
    "linReg.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = linReg.predict(X_test)\n",
    "\n",
    "print(\"RMSE:\", ((metrics.mean_squared_error(y_test, y_pred))**0.5))\n",
    "print(\"R2:\", (metrics.r2_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores:  [1.47154453e+01 5.89475357e-03 4.77812270e-03 3.95887090e-03\n",
      " 3.32884282e-03]\n",
      "Average CV Score:  2.946681174176296\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(linReg, X, y, cv = 5, scoring='neg_mean_squared_error')\n",
    "\n",
    "print(\"Cross Validation Scores: \", -scores)\n",
    "print(\"Average CV Score: \", -scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confussion Matrix\n",
      "[[180102   4311]\n",
      " [   244 184374]] \n",
      "\n",
      "Accuracy: 0.9876568635155312\n",
      "Precission: 0.9878937507540672\n",
      "Recall:  0.9876568635155312\n",
      "F1 Score:  0.9876552885775697\n",
      "Sensitivity: 0.9986783520566792\n",
      "Specificity: 0.9766231230986969\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "# Crear una instancia del modelo SVM y entrenarlo con diferentes parámetros\n",
    "logReg1 = LogisticRegression(solver='liblinear')\n",
    "logReg1.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = logReg1.predict(X_test)\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test,y_pred)\n",
    "\n",
    "print(\"Confussion Matrix\")\n",
    "print(cm,\"\\n\")\n",
    "print (\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print (\"Precission:\", metrics.precision_score(y_test,y_pred,average='weighted', zero_division=0))\n",
    "print (\"Recall: \", metrics.recall_score(y_test,y_pred,average='weighted', zero_division=0))\n",
    "print (\"F1 Score: \", metrics.f1_score(y_test,y_pred,average='weighted'))\n",
    "\n",
    "# Calcular la precisión (accuracy), sensibilidad (sensitivity) y especificidad (specificity)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "true_negative = confusion[0, 0]\n",
    "false_positive = confusion[0, 1]\n",
    "false_negative = confusion[1, 0]\n",
    "true_positive = confusion[1, 1]\n",
    "\n",
    "sensitivity = true_positive / (true_positive + false_negative)\n",
    "specificity = true_negative / (true_negative + false_positive)\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "print(\"Specificity:\", specificity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores:  [0.99221685 0.99267496 0.99456147 0.99490643 0.99451296]\n",
      "Average CV Score:  0.99377453299033\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(logReg1, X, y, cv = 5, scoring='accuracy')\n",
    "\n",
    "print(\"Cross Validation Scores: \", scores)\n",
    "print(\"Average CV Score: \", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yeyoc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confussion Matrix\n",
      "[[180093   4320]\n",
      " [   246 184372]] \n",
      "\n",
      "Accuracy: 0.987627055721606\n",
      "Precission: 0.9771055476649778\n",
      "Recall:  0.9986675188768159\n",
      "F1 Score:  0.9877688784120436\n",
      "Sensitivity: 0.9986675188768159\n",
      "Specificity: 0.9765743195978591\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "# Crear una instancia del modelo SVM y entrenarlo con diferentes parámetros\n",
    "logReg2 = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=100)\n",
    "logReg2.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = logReg2.predict(X_test)\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test,y_pred)\n",
    "\n",
    "print(\"Confussion Matrix\")\n",
    "print(cm,\"\\n\")\n",
    "print (\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print (\"Precission:\", metrics.precision_score(y_test,y_pred, zero_division=0))\n",
    "print (\"Recall: \", metrics.recall_score(y_test,y_pred, zero_division=0))\n",
    "print (\"F1 Score: \", metrics.f1_score(y_test,y_pred))\n",
    "\n",
    "# Calcular la precisión (accuracy), sensibilidad (sensitivity) y especificidad (specificity)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "true_negative = confusion[0, 0]\n",
    "false_positive = confusion[0, 1]\n",
    "false_negative = confusion[1, 0]\n",
    "true_positive = confusion[1, 1]\n",
    "\n",
    "sensitivity = true_positive / (true_positive + false_negative)\n",
    "specificity = true_negative / (true_negative + false_positive)\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "print(\"Specificity:\", specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yeyoc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\yeyoc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\yeyoc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\yeyoc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores:  [0.99054595 0.99113341 0.99450757 0.99460459 0.99456686]\n",
      "Average CV Score:  0.9930716759239011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yeyoc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(logReg2, X, y, cv = 5, scoring='accuracy')\n",
    "\n",
    "print(\"Cross Validation Scores: \", scores)\n",
    "print(\"Average CV Score: \", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yeyoc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confussion Matrix\n",
      "[[179852   4561]\n",
      " [   272 184346]] \n",
      "\n",
      "Accuracy: 0.9869035392690587\n",
      "Precission: 0.9758558444102124\n",
      "Recall:  0.9985266875385932\n",
      "F1 Score:  0.987061107020949\n",
      "Sensitivity: 0.9985266875385932\n",
      "Specificity: 0.9752674702976472\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "# Crear una instancia del modelo SVM y entrenarlo con diferentes parámetros\n",
    "logReg3 = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=1000)\n",
    "logReg3.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = logReg3.predict(X_test)\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test,y_pred)\n",
    "\n",
    "print(\"Confussion Matrix\")\n",
    "print(cm,\"\\n\")\n",
    "print (\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print (\"Precission:\", metrics.precision_score(y_test,y_pred, zero_division=0))\n",
    "print (\"Recall: \", metrics.recall_score(y_test,y_pred, zero_division=0))\n",
    "print (\"F1 Score: \", metrics.f1_score(y_test,y_pred))\n",
    "\n",
    "# Calcular la precisión (accuracy), sensibilidad (sensitivity) y especificidad (specificity)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "true_negative = confusion[0, 0]\n",
    "false_positive = confusion[0, 1]\n",
    "false_negative = confusion[1, 0]\n",
    "true_positive = confusion[1, 1]\n",
    "\n",
    "sensitivity = true_positive / (true_positive + false_negative)\n",
    "specificity = true_negative / (true_negative + false_positive)\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "print(\"Specificity:\", specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yeyoc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\yeyoc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\yeyoc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\yeyoc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores:  [0.99228692 0.99272886 0.99420034 0.99521366 0.99471778]\n",
      "Average CV Score:  0.9938295111391057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yeyoc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(logReg3, X, y, cv = 5, scoring='accuracy')\n",
    "\n",
    "print(\"Cross Validation Scores: \", scores)\n",
    "print(\"Average CV Score: \", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "\n",
    "\n",
    "# Crear una instancia del modelo SVM y entrenarlo con diferentes parámetros\n",
    "rfr = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rfr.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = rfr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.002450216455024807\n",
      "R2: 0.9999759857498836\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE:\", ((metrics.mean_squared_error(y_test, y_pred))**0.5))\n",
    "print(\"R2:\", (metrics.r2_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores:  [3.77299506e-09 1.83260748e-08 2.34951059e-06 2.37214868e-06\n",
      " 5.71396231e-06]\n",
      "Average CV Score:  2.091544129432759e-06\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(rfr, X, y, cv = 5, scoring='neg_mean_squared_error')\n",
    "\n",
    "print(\"Cross Validation Scores: \", -scores)\n",
    "print(\"Average CV Score: \", -scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confussion Matrix\n",
      "[[184413      0]\n",
      " [     0 184618]] \n",
      "\n",
      "Accuracy: 1.0\n",
      "Precission: 1.0\n",
      "Recall:  1.0\n",
      "F1 Score:  1.0\n",
      "Sensitivity: 1.0\n",
      "Specificity: 1.0\n"
     ]
    }
   ],
   "source": [
    "cm = metrics.confusion_matrix(y_test,y_pred)\n",
    "\n",
    "print(\"Confussion Matrix\")\n",
    "print(cm,\"\\n\")\n",
    "print (\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print (\"Precission:\", metrics.precision_score(y_test,y_pred,average='weighted', zero_division=0))\n",
    "print (\"Recall: \", metrics.recall_score(y_test,y_pred,average='weighted', zero_division=0))\n",
    "print (\"F1 Score: \", metrics.f1_score(y_test,y_pred,average='weighted'))\n",
    "\n",
    "# Calcular la precisión (accuracy), sensibilidad (sensitivity) y especificidad (specificity)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "true_negative = confusion[0, 0]\n",
    "false_positive = confusion[0, 1]\n",
    "false_negative = confusion[1, 0]\n",
    "true_positive = confusion[1, 1]\n",
    "\n",
    "sensitivity = true_positive / (true_positive + false_negative)\n",
    "specificity = true_negative / (true_negative + false_positive)\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "print(\"Specificity:\", specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores:  [0.59239256 1.         0.99998922 0.99997844 0.99998922]\n",
      "Average CV Score:  0.9184698887579621\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(rf, X, y, cv = 5, scoring='accuracy')\n",
    "\n",
    "print(\"Cross Validation Scores: \", scores)\n",
    "print(\"Average CV Score: \", scores.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
